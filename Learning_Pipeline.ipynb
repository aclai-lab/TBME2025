{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/l30/.local/lib/python3.12/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redirect output to a file named by the current date and time\n",
    "current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_file_name = f\"{current_time}.txt\"\n",
    "sys.stdout = open(output_file_name, \"w\")\n",
    "\n",
    "# Define the binarization windows\n",
    "binarization_windows = [\n",
    "    ([0, 25], [26, 50]),\n",
    "    ([0, 21], [32, 50]),\n",
    "    ([0, 16], [37, 50]),\n",
    "    ([0, 11], [42, 50])\n",
    "]\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"ResidualProducts/ID-Features-Vote.csv\"\n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Genetic Algorithm configuration\n",
    "num_generations = 100\n",
    "population_size = 50\n",
    "\n",
    "def evaluate_individual(individual, X, y):\n",
    "    selected_features = [bool(gene) for gene in individual]\n",
    "    if len(selected_features) != X.shape[1]:\n",
    "        raise ValueError(f\"Dimension mismatch: {len(selected_features)} != {X.shape[1]}\")\n",
    "    if sum(selected_features) == 0:\n",
    "        return 0.0,\n",
    "    X_selected = X[:, selected_features]\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    scores = cross_val_score(clf, X_selected, y, cv=skf, scoring=\"accuracy\")\n",
    "    return np.mean(scores),\n",
    "\n",
    "for idx, (class_0_range, class_1_range) in enumerate(binarization_windows):\n",
    "    print(f\"Processing binarization window {idx + 1}: 0->{class_0_range}, 1->{class_1_range}\")\n",
    "\n",
    "    def binarize_vote(vote):\n",
    "        if class_0_range[0] <= vote <= class_0_range[1]:\n",
    "            return 0\n",
    "        elif class_1_range[0] <= vote <= class_1_range[1]:\n",
    "            return 1\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    dataset[f\"binary_vote_{idx}\"] = dataset[\"vote\"].apply(binarize_vote)\n",
    "    filtered_dataset = dataset.dropna(subset=[f\"binary_vote_{idx}\"])\n",
    "    filtered_dataset[f\"binary_vote_{idx}\"] = filtered_dataset[f\"binary_vote_{idx}\"].astype(int)\n",
    "\n",
    "    X = filtered_dataset.drop(columns=[\"ID\", \"PAINTING\", \"vote\", f\"binary_vote_{idx}\"]).values\n",
    "    y = filtered_dataset[f\"binary_vote_{idx}\"].values\n",
    "\n",
    "    class_counts = filtered_dataset[f\"binary_vote_{idx}\"].value_counts()\n",
    "    minority_class = class_counts.idxmin()\n",
    "    majority_class = class_counts.idxmax()\n",
    "\n",
    "    minority_data = filtered_dataset[filtered_dataset[f\"binary_vote_{idx}\"] == minority_class]\n",
    "    majority_data = filtered_dataset[filtered_dataset[f\"binary_vote_{idx}\"] == majority_class]\n",
    "    majority_downsampled = majority_data.sample(len(minority_data), random_state=42)\n",
    "    balanced_dataset = pd.concat([minority_data, majority_downsampled]).sample(frac=1, random_state=42)\n",
    "\n",
    "    X_balanced = balanced_dataset.drop(columns=[\"ID\", \"PAINTING\", \"vote\", f\"binary_vote_{idx}\"]).values\n",
    "    y_balanced = balanced_dataset[f\"binary_vote_{idx}\"].values\n",
    "\n",
    "    num_features = X_balanced.shape[1]\n",
    "    print(f\"Number of features: {num_features}\")\n",
    "\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=num_features)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    toolbox.register(\"evaluate\", evaluate_individual, X=X_balanced, y=y_balanced)\n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    population = toolbox.population(n=population_size)\n",
    "    hall_of_fame = tools.HallOfFame(1)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    population, log = algorithms.eaSimple(\n",
    "        population, toolbox, cxpb=0.5, mutpb=0.2, ngen=num_generations,\n",
    "        stats=stats, halloffame=hall_of_fame, verbose=True\n",
    "    )\n",
    "\n",
    "    best_individual = hall_of_fame[0]\n",
    "    selected_features = [i for i, gene in enumerate(best_individual) if gene == 1]\n",
    "\n",
    "    X_selected = X_balanced[:, selected_features]\n",
    "    final_model = RandomForestClassifier(random_state=42)\n",
    "    final_model.fit(X_selected, y_balanced)\n",
    "\n",
    "    y_pred = final_model.predict(X_selected)\n",
    "    accuracy = accuracy_score(y_balanced, y_pred)\n",
    "    sensitivity = recall_score(y_balanced, y_pred, pos_label=1)\n",
    "    specificity = recall_score(y_balanced, y_pred, pos_label=0)\n",
    "    precision = precision_score(y_balanced, y_pred, pos_label=1)\n",
    "    confusion = confusion_matrix(y_balanced, y_pred)\n",
    "    npv = confusion[0, 0] / (confusion[0, 0] + confusion[0, 1]) if (confusion[0, 0] + confusion[0, 1]) > 0 else 0\n",
    "\n",
    "    model_file = f\"ResidualProducts/final_model_window_{idx + 1}.pkl\"\n",
    "    with open(model_file, \"wb\") as f:\n",
    "        pickle.dump(final_model, f)\n",
    "\n",
    "    print(f\"Binarization Window {idx + 1} Results:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Sensitivity: {sensitivity}\")\n",
    "    print(f\"Specificity: {specificity}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"NPV: {npv}\")\n",
    "    print(f\"Selected Features: {selected_features}\")\n",
    "\n",
    "    gen = log.select(\"gen\")\n",
    "    avg = log.select(\"avg\")\n",
    "    max_ = log.select(\"max\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(gen, avg, label=\"Average Fitness\")\n",
    "    plt.plot(gen, max_, label=\"Max Fitness\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Fitness\")\n",
    "    plt.title(f\"Genetic Algorithm Performance for Window {idx + 1}\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"ResidualProducts/genetic_algorithm_performance_window_{idx + 1}.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Close the redirected output\n",
    "sys.stdout.close()\n",
    "# Reset stdout to default\n",
    "sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7372/2681827132.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_dataset[f\"binary_vote_{idx}\"] = filtered_dataset[f\"binary_vote_{idx}\"].astype(int)\n",
      "/tmp/ipykernel_7372/2681827132.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_dataset[f\"binary_vote_{idx}\"] = filtered_dataset[f\"binary_vote_{idx}\"].astype(int)\n",
      "/tmp/ipykernel_7372/2681827132.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_dataset[f\"binary_vote_{idx}\"] = filtered_dataset[f\"binary_vote_{idx}\"].astype(int)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "import pickle\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "# Create an output file with a timestamp\n",
    "current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output_file_name = f\"{current_time}.txt\"\n",
    "\n",
    "with open(output_file_name, \"w\") as output_file:\n",
    "    sys.stdout = output_file\n",
    "\n",
    "    # Define binarization windows for the 'vote' column\n",
    "    binarization_windows = [\n",
    "        ([0, 25], [26, 50]),\n",
    "        ([0, 21], [32, 50]),\n",
    "        ([0, 16], [37, 50]),\n",
    "        ([0, 11], [42, 50])\n",
    "    ]\n",
    "\n",
    "    # Load the dataset\n",
    "    file_path = \"ResidualProducts/ID-Features-Vote.csv\"\n",
    "    dataset = pd.read_csv(file_path)\n",
    "\n",
    "    # Extract feature names excluding non-relevant columns\n",
    "    feature_names = dataset.columns.difference([\"ID\", \"PAINTING\", \"vote\"])\n",
    "\n",
    "    for idx, (class_0_range, class_1_range) in enumerate(binarization_windows):\n",
    "        print(f\"Processing binarization window {idx + 1}: 0->{class_0_range}, 1->{class_1_range}\")\n",
    "\n",
    "        # Function to binarize the 'vote' column\n",
    "        def binarize_vote(vote):\n",
    "            if class_0_range[0] <= vote <= class_0_range[1]:\n",
    "                return 0\n",
    "            elif class_1_range[0] <= vote <= class_1_range[1]:\n",
    "                return 1\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "        # Apply binarization and filter invalid rows\n",
    "        dataset[f\"binary_vote_{idx}\"] = dataset[\"vote\"].apply(binarize_vote)\n",
    "        filtered_dataset = dataset.dropna(subset=[f\"binary_vote_{idx}\"])\n",
    "        filtered_dataset[f\"binary_vote_{idx}\"] = filtered_dataset[f\"binary_vote_{idx}\"].astype(int)\n",
    "\n",
    "        # Prepare feature matrix and target vector\n",
    "        X = filtered_dataset[feature_names].values\n",
    "        y = filtered_dataset[f\"binary_vote_{idx}\"].values\n",
    "\n",
    "        # 5-Fold Cross-Validation evaluation\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "        accuracy_scores = []\n",
    "        sensitivity_scores = []\n",
    "        specificity_scores = []\n",
    "        precision_scores = []\n",
    "        npv_scores = []\n",
    "\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Compute evaluation metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            sensitivity = recall_score(y_test, y_pred, pos_label=1)\n",
    "            specificity = recall_score(y_test, y_pred, pos_label=0)\n",
    "            precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "            confusion = confusion_matrix(y_test, y_pred)\n",
    "            npv = confusion[0, 0] / (confusion[0, 0] + confusion[0, 1]) if (confusion[0, 0] + confusion[0, 1]) > 0 else 0\n",
    "\n",
    "            # Store scores for averaging\n",
    "            accuracy_scores.append(accuracy)\n",
    "            sensitivity_scores.append(sensitivity)\n",
    "            specificity_scores.append(specificity)\n",
    "            precision_scores.append(precision)\n",
    "            npv_scores.append(npv)\n",
    "\n",
    "        # Calculate mean metrics across the 5 folds\n",
    "        avg_accuracy = np.mean(accuracy_scores)\n",
    "        avg_sensitivity = np.mean(sensitivity_scores)\n",
    "        avg_specificity = np.mean(specificity_scores)\n",
    "        avg_precision = np.mean(precision_scores)\n",
    "        avg_npv = np.mean(npv_scores)\n",
    "\n",
    "        # Save the trained model for this window\n",
    "        model_filename = f\"ResidualProducts/final_model_window_{idx + 1}.pkl\"\n",
    "        with open(model_filename, \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "        # Extract feature importances\n",
    "        feature_importances = model.feature_importances_\n",
    "        sorted_indices = np.argsort(feature_importances)[::-1]\n",
    "        top_features = [(feature_names[i], feature_importances[i]) for i in sorted_indices[:10]]\n",
    "\n",
    "        # Print the evaluation results and top features\n",
    "        print(f\"Results for Binarization Window {idx + 1}:\")\n",
    "        print(f\"Accuracy: {avg_accuracy:.4f}\")\n",
    "        print(f\"Sensitivity: {avg_sensitivity:.4f}\")\n",
    "        print(f\"Specificity: {avg_specificity:.4f}\")\n",
    "        print(f\"Precision (PPV): {avg_precision:.4f}\")\n",
    "        print(f\"Negative Predictive Value (NPV): {avg_npv:.4f}\")\n",
    "        print(\"\\nTop 10 Important Features:\")\n",
    "        for feature, importance in top_features:\n",
    "            print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "        sys.stdout.flush()\n",
    "        print('\\n\\n')\n",
    "\n",
    "    print(\"Processing completed successfully.\")\n",
    "\n",
    "# Restore standard output to console\n",
    "sys.stdout = sys.__stdout__\n",
    "print(f\"Results saved to {output_file_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
